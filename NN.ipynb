{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import keras\n",
    "from keras.models import Model\n",
    "from keras.layers import Conv1D, MaxPooling1D, Dense, Lambda, concatenate, Input, GlobalMaxPooling1D, GlobalAveragePooling1D\n",
    "import keras.backend as K\n",
    "import pandas as pd\n",
    "import json\n",
    "import pickle\n",
    "import random\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_frames = 599\n",
    "num_freq_bins = 128\n",
    "dummy_data = np.random.random((num_frames, num_freq_bins))\n",
    "num_conv_filters_1 = 256\n",
    "kernel_size = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def l2_norm(x):\n",
    "    x = x ** 2\n",
    "    x = K.sum(x, axis=1)\n",
    "    x = K.sqrt(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AudioCNNModel():\n",
    "    def __init__(self, num_frames, num_freq_bins, num_conv_filters1, pool_size_1, kernel_size):\n",
    "        \n",
    "        self.num_frames = num_frames\n",
    "        self.num_freq_bins = num_freq_bins\n",
    "        self.num_conv_filters1 = num_conv_filters1\n",
    "        self.pool_size1 = pool_size_1\n",
    "        self.kernel_size = kernel_size\n",
    "        self.model_input = Input(shape=(num_frames, num_freq_bins))\n",
    "        \n",
    "        x = Conv1D(filters=self.num_conv_filters1, kernel_size=self.kernel_size, input_shape=(self.num_frames, self.num_freq_bins))(self.model_input)\n",
    "        x = MaxPooling1D(pool_size=self.pool_size1)(x)\n",
    "        x = Conv1D(filters=256, kernel_size=self.kernel_size)(x)\n",
    "        x = MaxPooling1D(pool_size=2)(x)\n",
    "        x = Conv1D(filters=512, kernel_size=self.kernel_size)(x)\n",
    "        x = MaxPooling1D(pool_size=2)(x)\n",
    "\n",
    "        #temporal pooling, L2, mean\n",
    "        max_layer = GlobalMaxPooling1D(data_format='channels_last')(x)\n",
    "        mean_layer = GlobalAveragePooling1D(data_format='channels_last')(x)\n",
    "        L2_layer = Lambda(lambda x: l2_norm(x))(x)\n",
    "        #TODO:concatenate\n",
    "        \n",
    "        x = concatenate([max_layer, mean_layer, L2_layer])\n",
    "        #End\n",
    "        x = Dense(2048, activation='relu')(x)\n",
    "        x = Dense(2048, activation='relu')(x)\n",
    "        latent_factors = Dense(50)(x)\n",
    "        self.net = Model(inputs=self.model_input, outputs=latent_factors)\n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 50)"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = AudioCNNModel(num_frames, num_freq_bins, num_conv_filters_1, 4, kernel_size)\n",
    "model.net.predict(np.array([dummy_data])).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7457, 300, 12)\n"
     ]
    }
   ],
   "source": [
    "f = open(\"data/chroma.npy\", \"rb\")\n",
    "features = np.load(f)\n",
    "print(features.shape)\n",
    "f.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  4.6740026 ,  -9.249433  ,  -1.3980534 ,  26.877184  ,\n",
       "         -0.83539367, -16.137814  , -13.544751  ,  -0.743586  ,\n",
       "        -13.395603  ,  -1.2896507 , -12.627663  ,  -3.1189494 ,\n",
       "        -16.375254  ,   9.278057  ,  11.357858  ,  -6.0458646 ,\n",
       "        -13.366302  , -28.689785  ,   9.980033  ,   1.921149  ,\n",
       "         -0.8705852 ,  14.232031  ,  24.4798    ,  -5.9997387 ,\n",
       "        -10.810645  ,  -4.9090867 ,  17.26567   , -33.375454  ,\n",
       "         -6.5144606 ,   2.1467118 ,   9.165983  ,  27.146532  ,\n",
       "          0.09802441, -18.815805  ,   4.780112  ,   6.260415  ,\n",
       "         10.078434  ,   5.7494774 ,  11.292911  ,  -6.909471  ,\n",
       "        -17.60566   , -16.109322  , -15.617443  ,   4.06311   ,\n",
       "        -18.56289   , -35.05837   ,  17.217773  ,  13.385312  ,\n",
       "         43.127274  ,  -0.63544846]], dtype=float32)"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = AudioCNNModel(300, 12, num_conv_filters_1, 4, kernel_size)\n",
    "model.net.predict(np.array([features[0]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/song-track-mapping.json', 'rb') as fp:\n",
    "    song_track_mapping = json.load(fp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/track-song-mapping.json', 'rb') as fp:\n",
    "    track_song_mapping = json.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRBBQGV12903CB5CD3 SOSIANM12AB018CC80\n"
     ]
    }
   ],
   "source": [
    "print(song_track_mapping['SOSIANM12AB018CC80'], track_song_mapping['TRBBQGV12903CB5CD3'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.loc[df['song'] == 'SOSIANM12AB018CC80']['features'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.16932662, -0.08086438,  0.06148606, -0.04873373,  0.04393521,\n",
       "        0.10009863, -0.01554874, -0.12346692, -0.04547898,  0.13980697,\n",
       "        0.08787304, -0.18935911,  0.03744032,  0.12680109, -0.00610406,\n",
       "       -0.0684809 , -0.04503168,  0.14103816,  0.01458193, -0.0455489 ,\n",
       "        0.10926478, -0.03594866,  0.16459042,  0.08418246, -0.00514472,\n",
       "        0.1974538 ,  0.15211657,  0.01583795, -0.01534751, -0.08645362,\n",
       "       -0.04650037,  0.00193394,  0.02213042, -0.10820573, -0.01231078,\n",
       "       -0.10624152, -0.1368499 ,  0.10162297, -0.15660124,  0.28276092,\n",
       "        0.04303405,  0.06791999,  0.09406953,  0.01736024, -0.19946253,\n",
       "        0.01771   , -0.04061035,  0.23670618, -0.02108839,  0.05780403])"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('data/song_factors.pkl', 'rb') as f:\n",
    "    song_factors_dict = pickle.load(f)\n",
    "np.array(song_factors_dict['SOSIANM12AB018CC80'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "track_features_dict = {}\n",
    "f = open(\"data/track_ids_for_chroma.txt\", \"r\")\n",
    "counter = 0\n",
    "for line in f:\n",
    "    track_features_dict[line.strip()] = new_l[counter]\n",
    "    counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.net.compile(loss=keras.losses.mean_squared_error, optimizer=keras.optimizers.Adam(lr=1e-5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "track_id_set = track_features_dict.keys()\n",
    "song_id_set = list(song_factors_dict.keys())\n",
    "count = 0\n",
    "for song_id_key in song_id_set:\n",
    "    if song_track_mapping[str(song_id_key)] not in track_id_set:\n",
    "        count +=1\n",
    "#         print(song_track_mapping[song_id_key])\n",
    "        del song_factors_dict[song_id_key]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "# song_factors_dict\n",
    "keys = song_factors_dict.keys()\n",
    "track_id_list = [song_track_mapping[key] for key in keys]\n",
    "y = np.array([np.array(song_factors_dict[song_id]) for song_id in keys])\n",
    "x = np.array([track_features_dict[track_id] for track_id in track_id_list])\n",
    "# x = sklearn.preprocessing.normalize(x, norm='l2', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2188, 300, 12) (2188, 50)\n",
      "Epoch 1/20\n",
      "2188/2188 [==============================] - 17s 8ms/step - loss: 22.9020\n",
      "Epoch 2/20\n",
      "2188/2188 [==============================] - 17s 8ms/step - loss: 1.3049\n",
      "Epoch 3/20\n",
      "2188/2188 [==============================] - 18s 8ms/step - loss: 0.8773\n",
      "Epoch 4/20\n",
      "2188/2188 [==============================] - 16s 8ms/step - loss: 0.6837\n",
      "Epoch 5/20\n",
      "2188/2188 [==============================] - 16s 8ms/step - loss: 0.5637\n",
      "Epoch 6/20\n",
      "2188/2188 [==============================] - 17s 8ms/step - loss: 0.4798\n",
      "Epoch 7/20\n",
      "2188/2188 [==============================] - 17s 8ms/step - loss: 0.4159\n",
      "Epoch 8/20\n",
      "2188/2188 [==============================] - 17s 8ms/step - loss: 0.3654\n",
      "Epoch 9/20\n",
      "2188/2188 [==============================] - 17s 8ms/step - loss: 0.3263\n",
      "Epoch 10/20\n",
      "2188/2188 [==============================] - 16s 8ms/step - loss: 0.2930\n",
      "Epoch 11/20\n",
      "2188/2188 [==============================] - 22s 10ms/step - loss: 0.2659\n",
      "Epoch 12/20\n",
      "2188/2188 [==============================] - 16s 7ms/step - loss: 0.2438\n",
      "Epoch 13/20\n",
      "2188/2188 [==============================] - 17s 8ms/step - loss: 0.2254\n",
      "Epoch 14/20\n",
      "2188/2188 [==============================] - 17s 8ms/step - loss: 0.2079\n",
      "Epoch 15/20\n",
      "2188/2188 [==============================] - 17s 8ms/step - loss: 0.1921\n",
      "Epoch 16/20\n",
      "2188/2188 [==============================] - 17s 8ms/step - loss: 0.1796\n",
      "Epoch 17/20\n",
      "2188/2188 [==============================] - 17s 8ms/step - loss: 0.1662\n",
      "Epoch 18/20\n",
      "2188/2188 [==============================] - 17s 8ms/step - loss: 0.1579\n",
      "Epoch 19/20\n",
      "2188/2188 [==============================] - 17s 8ms/step - loss: 0.1492\n",
      "Epoch 20/20\n",
      "2188/2188 [==============================] - 17s 8ms/step - loss: 0.1397\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f3c3767a1d0>"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "xTrain, xTest, yTrain, yTest = train_test_split(x, y, test_size = 0.2, random_state = 0)\n",
    "print(xTrain.shape, yTrain.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "2188/2188 [==============================] - 18s 8ms/step - loss: 0.0304\n",
      "Epoch 2/20\n",
      "2188/2188 [==============================] - 17s 8ms/step - loss: 0.0279\n",
      "Epoch 3/20\n",
      "2188/2188 [==============================] - 17s 8ms/step - loss: 0.0267\n",
      "Epoch 4/20\n",
      "2188/2188 [==============================] - 17s 8ms/step - loss: 0.0256\n",
      "Epoch 5/20\n",
      "2188/2188 [==============================] - 17s 8ms/step - loss: 0.0257\n",
      "Epoch 6/20\n",
      "2188/2188 [==============================] - 17s 8ms/step - loss: 0.0249\n",
      "Epoch 7/20\n",
      "2188/2188 [==============================] - 17s 8ms/step - loss: 0.0238\n",
      "Epoch 8/20\n",
      "2188/2188 [==============================] - 17s 8ms/step - loss: 0.0225\n",
      "Epoch 9/20\n",
      "2188/2188 [==============================] - 17s 8ms/step - loss: 0.0217\n",
      "Epoch 10/20\n",
      "2188/2188 [==============================] - 17s 8ms/step - loss: 0.0207\n",
      "Epoch 11/20\n",
      "2188/2188 [==============================] - 18s 8ms/step - loss: 0.0199\n",
      "Epoch 12/20\n",
      "2188/2188 [==============================] - 21s 9ms/step - loss: 0.0193\n",
      "Epoch 13/20\n",
      "2188/2188 [==============================] - 19s 9ms/step - loss: 0.0182\n",
      "Epoch 14/20\n",
      "2188/2188 [==============================] - 16s 7ms/step - loss: 0.0180\n",
      "Epoch 15/20\n",
      "2188/2188 [==============================] - 16s 7ms/step - loss: 0.0176\n",
      "Epoch 16/20\n",
      "2188/2188 [==============================] - 16s 7ms/step - loss: 0.0168\n",
      "Epoch 17/20\n",
      "2188/2188 [==============================] - 16s 7ms/step - loss: 0.0163\n",
      "Epoch 18/20\n",
      "2188/2188 [==============================] - 16s 7ms/step - loss: 0.0158\n",
      "Epoch 19/20\n",
      "2188/2188 [==============================] - 16s 7ms/step - loss: 0.0151\n",
      "Epoch 20/20\n",
      "2188/2188 [==============================] - 16s 7ms/step - loss: 0.0146\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f3c32afcac8>"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.net.fit(xTrain, yTrain, epochs=20, batch_size=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_y = (np.linalg.norm(yTest)**2)/yTest.shape[0]\n",
    "pred = model.net.predict(xTest)\n",
    "norm_pred = (np.linalg.norm(pred)**2)/pred.shape[0]\n",
    "norm_y_train = (np.linalg.norm(yTrain)**2)/yTrain.shape[0]\n",
    "train_pred = model.net.predict(xTrain)\n",
    "# norm_pred_train = (np.linalg.norm(train_pred)**2)/train_pred.shape[0]\n",
    "# avg_loss_test = (np.linalg.norm(yTest-pred)**2)/yTest.shape[0]\n",
    "# loss_train = np.linalg.norm(yTrain - train_pred)**2\n",
    "# avg_loss_train = loss_train/yTrain.shape[0]\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average train loss 0.013648288253064815\n",
      "average test loss 0.0902450124428803\n",
      "average train norm 0.0017976001065020996\n",
      "average test norm 0.0013229732227013138\n",
      "average norm of predictions 0.013672692\n"
     ]
    }
   ],
   "source": [
    "avg_loss_train = np.mean(np.square(train_pred - yTrain))\n",
    "avg_loss_test = np.mean(np.square(pred - yTest))\n",
    "avg_pred_norm = np.mean(np.square(train_pred))\n",
    "norm_y_train = np.mean(np.square(yTrain))\n",
    "norm_y = np.mean(np.square(yTest))\n",
    "print(\"average train loss\",avg_loss_train)\n",
    "print(\"average test loss\", avg_loss_test)\n",
    "print(\"average train norm\",norm_y_train)\n",
    "print(\"average test norm\",norm_y)\n",
    "print(\"average norm of predictions\", avg_pred_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2735\n"
     ]
    }
   ],
   "source": [
    "print(len(list(song_factors_dict.keys())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "232.8407692922114\n"
     ]
    }
   ],
   "source": [
    "norm_sum = 0.0\n",
    "for song_id in song_factors_dict.keys():\n",
    "    y = np.array(song_factors_dict[song_id])\n",
    "    x = track_features_dict[song_track_mapping[str(song_id_key)]]\n",
    "#     y_pred = model.net.predict(np.array([x]))\n",
    "    norm_sum += np.linalg.norm(y)**2\n",
    "print(norm_sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_json = model.net.to_json()\n",
    "with open('params/model_params_v0.json', \"w\") as f:\n",
    "    f.write(model_json)\n",
    "model.net.save_weights(\"params/model_params_v0.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
