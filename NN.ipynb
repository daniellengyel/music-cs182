{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from keras.models import Model\n",
    "from keras.layers import Conv1D, MaxPooling1D, Dense, Lambda, concatenate, Input, GlobalMaxPooling1D, GlobalAveragePooling1D\n",
    "import keras.backend as K\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_frames = 599\n",
    "num_freq_bins = 128\n",
    "dummy_data = np.random.random((num_frames, num_freq_bins))\n",
    "num_conv_filters_1 = 256\n",
    "kernel_size = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def l2_norm(x):\n",
    "    x = x ** 2\n",
    "    x = K.sum(x, axis=1)\n",
    "    x = K.sqrt(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AudioCNNModel():\n",
    "    def __init__(self, num_frames, num_freq_bins, num_conv_filters1, pool_size_1, kernel_size):\n",
    "        \n",
    "        self.num_frames = num_frames\n",
    "        self.num_freq_bins = num_freq_bins\n",
    "        self.num_conv_filters1 = num_conv_filters1\n",
    "        self.pool_size1 = pool_size_1\n",
    "        self.kernel_size = kernel_size\n",
    "        self.model_input = Input(shape=(num_frames, num_freq_bins))\n",
    "        \n",
    "        x = Conv1D(filters=self.num_conv_filters1, kernel_size=self.kernel_size, input_shape=(self.num_frames, self.num_freq_bins))(self.model_input)\n",
    "        x = MaxPooling1D(pool_size=self.pool_size1)(x)\n",
    "        x = Conv1D(filters=256, kernel_size=self.kernel_size)(x)\n",
    "        x = MaxPooling1D(pool_size=2)(x)\n",
    "        x = Conv1D(filters=512, kernel_size=self.kernel_size)(x)\n",
    "        x = MaxPooling1D(pool_size=2)(x)\n",
    "\n",
    "        #temporal pooling, L2, mean\n",
    "        max_layer = GlobalMaxPooling1D(data_format='channels_last')(x)\n",
    "        mean_layer = GlobalAveragePooling1D(data_format='channels_last')(x)\n",
    "        L2_layer = Lambda(lambda x: l2_norm(x))(x)\n",
    "        #TODO:concatenate\n",
    "        \n",
    "        x = concatenate([max_layer, mean_layer, L2_layer])\n",
    "        #End\n",
    "        x = Dense(2048, activation='relu')(x)\n",
    "        x = Dense(2048, activation='relu')(x)\n",
    "        latent_factors = Dense(50)(x)\n",
    "        self.net = Model(inputs=self.model_input, outputs=latent_factors)\n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/dhruv/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1, 50)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = AudioCNNModel(num_frames, num_freq_bins, num_conv_filters_1, 4, kernel_size)\n",
    "model.net.predict(np.array([dummy_data])).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(588, 12)\n"
     ]
    }
   ],
   "source": [
    "sample = np.loadtxt(open(\"mfcc.csv\", \"rb\"), delimiter=\",\")\n",
    "print(sample.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.3768783e+01,  5.3400726e+00,  1.7182302e+01,  4.7254562e-03,\n",
       "         1.1371862e+01, -1.1489881e+01, -1.1623225e+01, -5.3368160e+01,\n",
       "         2.8220667e+01,  2.1207111e+00,  3.0441160e+01, -2.2382311e+01,\n",
       "         2.0941704e+01, -2.5579355e+01,  4.6951742e+00, -9.3095657e+01,\n",
       "        -3.8151526e+00,  2.1477886e+01, -3.1216588e+00, -1.1774329e+01,\n",
       "         3.5614014e+01,  7.8140297e+00, -1.8039911e+00, -1.8990763e+01,\n",
       "         6.0609093e+01, -2.6195520e+01,  2.7206783e+01, -2.3290064e+01,\n",
       "         1.4504442e+01, -2.5367855e+01, -6.3717075e+01,  1.2852405e+01,\n",
       "        -1.7351482e+01,  1.2951219e+01, -2.1215942e+01,  4.4176807e+01,\n",
       "         1.6976128e+01, -1.8742142e+01, -2.6397219e+00, -5.5945778e+01,\n",
       "         8.1725750e+00, -2.6101841e+01,  4.0300927e+00, -4.7360023e+01,\n",
       "        -7.8776133e-01,  5.5466011e+01, -1.3403375e+01, -3.0053848e+01,\n",
       "         1.3307592e+01,  5.9734659e+00]], dtype=float32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = AudioCNNModel(588, 12, num_conv_filters_1, 4, kernel_size)\n",
    "model.net.predict(np.array([sample]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7457, 300, 12)\n"
     ]
    }
   ],
   "source": [
    "f = open(\"chroma.npy\", \"rb\")\n",
    "new_l = np.load(f)\n",
    "print(new_l.shape)\n",
    "f.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-10.795193 , -22.549454 ,   9.735798 ,  -8.500256 ,  -5.311801 ,\n",
       "          4.7889986, -25.51222  , -10.607115 ,   5.5248623,  -0.1869241,\n",
       "         -5.0444384,   1.5588579,   1.2705004,   3.774472 ,   8.58127  ,\n",
       "         -5.629212 , -10.317668 ,  33.51322  ,  -5.630941 , -17.618286 ,\n",
       "         -6.794819 ,   2.2527916, -11.753466 ,  19.634468 ,  -9.071924 ,\n",
       "         10.407949 ,   2.977954 ,  -7.0899405,  -7.902363 , -20.436295 ,\n",
       "         -6.8034143, -17.229927 ,   4.1288157,  -1.3273693,   3.5205586,\n",
       "        -11.960981 , -45.609367 , -14.118712 ,   1.3335799, -20.939522 ,\n",
       "         18.94703  ,   8.75972  ,  -9.244462 , -13.868502 , -30.433079 ,\n",
       "          8.901087 ,  -2.844258 ,   4.8732414,   1.0633532,  15.935471 ]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = AudioCNNModel(300, 12, num_conv_filters_1, 4, kernel_size)\n",
    "model.net.predict(np.array([new_l[0]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
