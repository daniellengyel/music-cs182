{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import keras\n",
    "from keras.models import Model\n",
    "from keras.layers import Conv1D, MaxPooling1D, Dense, Lambda, concatenate, Input, GlobalMaxPooling1D, GlobalAveragePooling1D\n",
    "import keras.backend as K\n",
    "import pandas as pd\n",
    "import json\n",
    "import pickle\n",
    "import random\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_frames = 599\n",
    "num_freq_bins = 128\n",
    "dummy_data = np.random.random((num_frames, num_freq_bins))\n",
    "num_conv_filters_1 = 256\n",
    "kernel_size = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def l2_norm(x, axis):\n",
    "    x = x ** 2\n",
    "    x = K.sum(x, axis=axis)\n",
    "    x = K.sqrt(x)\n",
    "    return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AudioCNNModel():\n",
    "    def __init__(self, num_frames, num_freq_bins, num_conv_filters1, pool_size_1, kernel_size):\n",
    "        \n",
    "        self.num_frames = num_frames\n",
    "        self.num_freq_bins = num_freq_bins\n",
    "        self.num_conv_filters1 = num_conv_filters1\n",
    "        self.pool_size1 = pool_size_1\n",
    "        self.kernel_size = kernel_size\n",
    "        self.model_input = Input(shape=(num_frames, num_freq_bins))\n",
    "        \n",
    "        x = Conv1D(filters=self.num_conv_filters1, kernel_size=self.kernel_size, input_shape=(self.num_frames, self.num_freq_bins))(self.model_input)\n",
    "        x = MaxPooling1D(pool_size=self.pool_size1)(x)\n",
    "        x = Conv1D(filters=256, kernel_size=self.kernel_size)(x)\n",
    "        x = MaxPooling1D(pool_size=2)(x)\n",
    "        x = Conv1D(filters=512, kernel_size=self.kernel_size)(x)\n",
    "        x = MaxPooling1D(pool_size=2)(x)\n",
    "\n",
    "        #temporal pooling, L2, mean\n",
    "        max_layer = GlobalMaxPooling1D(data_format='channels_last')(x)\n",
    "        mean_layer = GlobalAveragePooling1D(data_format='channels_last')(x)\n",
    "        L2_layer = Lambda(lambda x: l2_norm(x, 1))(x)\n",
    "        #TODO:concatenate\n",
    "        \n",
    "        x = concatenate([max_layer, mean_layer, L2_layer])\n",
    "        #End\n",
    "        x = Dense(2048, activation='relu')(x)\n",
    "        x = Dense(2048, activation='relu')(x)\n",
    "#         latent_factors = Dense(50)(x)\n",
    "#         popularity = Lambda(lambda x: l2_norm(x, 0))(x)\n",
    "        x = Dense(50, activation='relu')(x)\n",
    "        #TODO: How many genres?\n",
    "        genre = Dense(num_genres, activation='softmax')\n",
    "        #TODO: How to make the output?\n",
    "        self.net = Model(inputs=self.model_input, outputs=genre)\n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/dhruv/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1, 50)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = AudioCNNModel(num_frames, num_freq_bins, num_conv_filters_1, 4, kernel_size)\n",
    "model.net.predict(np.array([dummy_data])).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7457, 300, 12)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 16.79 ,  85.44 , 190.534, ...,  78.221,  14.966,  -6.661],\n",
       "       [ 38.132, 103.244, 213.144, ...,  14.131,   3.21 ,  14.653],\n",
       "       [ 40.398,  88.145, 196.978, ...,   6.997, -19.436,  17.779],\n",
       "       ...,\n",
       "       [ 42.91 , -38.456,  91.888, ...,  -3.663, -23.66 ,  19.423],\n",
       "       [ 54.395,  58.726, -13.786, ...,   5.575,  17.883,   0.23 ],\n",
       "       [ 54.404,  58.62 , -12.292, ...,  10.572,   8.203,  -0.64 ]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f = open(\"data/chroma.npy\", \"rb\")\n",
    "features = np.load(f)\n",
    "print(features.shape)\n",
    "f.close()\n",
    "features[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.2497673e-02, 2.0416826e-02, 1.9186740e-03, 9.3376811e-04,\n",
       "        3.2154915e-03, 3.6675599e-03, 1.0267120e-03, 2.7087808e-03,\n",
       "        2.6695407e-03, 2.4735278e-03, 3.6028225e-02, 4.4548386e-05,\n",
       "        3.6557947e-04, 5.0733138e-06, 5.3241249e-02, 9.3602259e-03,\n",
       "        3.3786413e-03, 5.0325347e-03, 7.5308822e-02, 4.6164577e-04,\n",
       "        2.5875701e-03, 2.3309983e-02, 8.3400682e-03, 6.1439633e-02,\n",
       "        4.3262723e-03, 3.6562353e-02, 2.1284105e-02, 1.5371314e-03,\n",
       "        1.2346921e-02, 3.5836563e-02, 5.4558285e-04, 8.3356316e-04,\n",
       "        7.3790508e-03, 1.7735828e-03, 4.6333647e-03, 1.4051500e-03,\n",
       "        3.6401264e-03, 5.9511941e-03, 4.7053136e-02, 2.6834181e-03,\n",
       "        3.4554763e-04, 3.7510488e-02, 7.8907814e-03, 7.2197281e-03,\n",
       "        7.8275399e-03, 1.6686353e-03, 4.6824701e-03, 1.3274793e-02,\n",
       "        3.2971721e-02, 6.0954727e-03]], dtype=float32)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = AudioCNNModel(300, 12, num_conv_filters_1, 4, kernel_size)\n",
    "np.square(model.net.predict(np.array([normalize(features[0])])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/song-track-mapping.json', 'rb') as fp:\n",
    "    song_track_mapping = json.load(fp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/track-song-mapping.json', 'rb') as fp:\n",
    "    track_song_mapping = json.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRBBQGV12903CB5CD3 SOSIANM12AB018CC80\n"
     ]
    }
   ],
   "source": [
    "print(song_track_mapping['SOSIANM12AB018CC80'], track_song_mapping['TRBBQGV12903CB5CD3'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.loc[df['song'] == 'SOSIANM12AB018CC80']['features'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.86715037e-02, 6.53904872e-03, 3.78053578e-03, 2.37497606e-03,\n",
       "       1.93030263e-03, 1.00197362e-02, 2.41763361e-04, 1.52440813e-02,\n",
       "       2.06833737e-03, 1.95459891e-02, 7.72167145e-03, 3.58568739e-02,\n",
       "       1.40177774e-03, 1.60785160e-02, 3.72594914e-05, 4.68963386e-03,\n",
       "       2.02785235e-03, 1.98917638e-02, 2.12632571e-04, 2.07470238e-03,\n",
       "       1.19387913e-02, 1.29230644e-03, 2.70900058e-02, 7.08668592e-03,\n",
       "       2.64681244e-05, 3.89880019e-02, 2.31394499e-02, 2.50840798e-04,\n",
       "       2.35546081e-04, 7.47422783e-03, 2.16228440e-03, 3.74010632e-06,\n",
       "       4.89755673e-04, 1.17084796e-02, 1.51555296e-04, 1.12872599e-02,\n",
       "       1.87278938e-02, 1.03272278e-02, 2.45239469e-02, 7.99537368e-02,\n",
       "       1.85192951e-03, 4.61312530e-03, 8.84907565e-03, 3.01377876e-04,\n",
       "       3.97853021e-02, 3.13644110e-04, 1.64920058e-03, 5.60298168e-02,\n",
       "       4.44720258e-04, 3.34130625e-03])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('data/song_factors.pkl', 'rb') as f:\n",
    "    song_factors_dict = pickle.load(f)\n",
    "np.square(np.array(song_factors_dict['SOSIANM12AB018CC80']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "track_features_dict = {}\n",
    "f = open(\"data/track_ids_for_chroma.txt\", \"r\")\n",
    "counter = 0\n",
    "for line in f:\n",
    "    track_features_dict[line.strip()] = features[counter]\n",
    "    counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.net.compile(loss=keras.losses.mean_squared_error, optimizer=keras.optimizers.Adam(lr=1e-5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "track_id_set = track_features_dict.keys()\n",
    "song_id_set = list(song_factors_dict.keys())\n",
    "count = 0\n",
    "for song_id_key in song_id_set:\n",
    "    if song_track_mapping[str(song_id_key)] not in track_id_set:\n",
    "        count +=1\n",
    "#         print(song_track_mapping[song_id_key])\n",
    "        del song_factors_dict[song_id_key]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# song_factors_dict\n",
    "keys = song_factors_dict.keys()\n",
    "track_id_list = [song_track_mapping[key] for key in keys]\n",
    "y = np.array([np.array(song_factors_dict[song_id]) for song_id in keys])\n",
    "x = np.array([normalize(track_features_dict[track_id]) for track_id in track_id_list])\n",
    "# x = sklearn.preprocessing.normalize(x, norm='l2', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2188, 300, 12) (2188, 50)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "xTrain, xTest, yTrain, yTest = train_test_split(x, y, test_size = 0.2, random_state = 0)\n",
    "print(xTrain.shape, yTrain.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/dhruv/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING:tensorflow:From /home/dhruv/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/math_grad.py:102: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Deprecated in favor of operator or tf.math.divide.\n",
      "Epoch 1/20\n",
      "2188/2188 [==============================] - 16s 7ms/step - loss: 0.0041\n",
      "Epoch 2/20\n",
      "2188/2188 [==============================] - 16s 7ms/step - loss: 0.0022\n",
      "Epoch 3/20\n",
      "2188/2188 [==============================] - 16s 7ms/step - loss: 0.0021\n",
      "Epoch 4/20\n",
      "2188/2188 [==============================] - 16s 7ms/step - loss: 0.0020\n",
      "Epoch 5/20\n",
      "2188/2188 [==============================] - 16s 7ms/step - loss: 0.0019\n",
      "Epoch 6/20\n",
      "2188/2188 [==============================] - 16s 7ms/step - loss: 0.0019\n",
      "Epoch 7/20\n",
      "2188/2188 [==============================] - 16s 7ms/step - loss: 0.0019\n",
      "Epoch 8/20\n",
      "2188/2188 [==============================] - 16s 7ms/step - loss: 0.0019\n",
      "Epoch 9/20\n",
      "2188/2188 [==============================] - 16s 7ms/step - loss: 0.0018\n",
      "Epoch 10/20\n",
      "2188/2188 [==============================] - 16s 7ms/step - loss: 0.0018\n",
      "Epoch 11/20\n",
      "2188/2188 [==============================] - 16s 7ms/step - loss: 0.0018\n",
      "Epoch 12/20\n",
      "2188/2188 [==============================] - 16s 7ms/step - loss: 0.0018\n",
      "Epoch 13/20\n",
      "2188/2188 [==============================] - 16s 7ms/step - loss: 0.0018\n",
      "Epoch 14/20\n",
      "2188/2188 [==============================] - 16s 7ms/step - loss: 0.0018\n",
      "Epoch 15/20\n",
      "2188/2188 [==============================] - 16s 7ms/step - loss: 0.0018\n",
      "Epoch 16/20\n",
      "2188/2188 [==============================] - 16s 7ms/step - loss: 0.0017\n",
      "Epoch 17/20\n",
      "2188/2188 [==============================] - 16s 7ms/step - loss: 0.0017\n",
      "Epoch 18/20\n",
      "2188/2188 [==============================] - 16s 7ms/step - loss: 0.0017\n",
      "Epoch 19/20\n",
      "2188/2188 [==============================] - 16s 7ms/step - loss: 0.0017\n",
      "Epoch 20/20\n",
      "2188/2188 [==============================] - 16s 7ms/step - loss: 0.0017\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f5aa438ba90>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.net.fit(xTrain, yTrain, epochs=20, batch_size=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_y = (np.linalg.norm(yTest)**2)/yTest.shape[0]\n",
    "pred = model.net.predict(xTest)\n",
    "norm_pred = (np.linalg.norm(pred)**2)/pred.shape[0]\n",
    "norm_y_train = (np.linalg.norm(yTrain)**2)/yTrain.shape[0]\n",
    "train_pred = model.net.predict(xTrain)\n",
    "# norm_pred_train = (np.linalg.norm(train_pred)**2)/train_pred.shape[0]\n",
    "# avg_loss_test = (np.linalg.norm(yTest-pred)**2)/yTest.shape[0]\n",
    "# loss_train = np.linalg.norm(yTrain - train_pred)**2\n",
    "# avg_loss_train = loss_train/yTrain.shape[0]\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average train loss 0.001681504540678089\n",
      "average test loss 0.00146909312721303\n",
      "average train norm 0.0017976001065020996\n",
      "average test norm 0.0013229732227013138\n",
      "average norm of predictions 0.00018282322\n"
     ]
    }
   ],
   "source": [
    "avg_loss_train = np.mean(np.square(train_pred - yTrain))\n",
    "avg_loss_test = np.mean(np.square(pred - yTest))\n",
    "avg_pred_norm = np.mean(np.square(train_pred))\n",
    "norm_y_train = np.mean(np.square(yTrain))\n",
    "norm_y = np.mean(np.square(yTest))\n",
    "print(\"average train loss\",avg_loss_train)\n",
    "print(\"average test loss\", avg_loss_test)\n",
    "print(\"average train norm\",norm_y_train)\n",
    "print(\"average test norm\",norm_y)\n",
    "print(\"average norm of predictions\", avg_pred_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2735\n"
     ]
    }
   ],
   "source": [
    "print(len(list(song_factors_dict.keys())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "232.8407692922114\n"
     ]
    }
   ],
   "source": [
    "norm_sum = 0.0\n",
    "for song_id in song_factors_dict.keys():\n",
    "    y = np.array(song_factors_dict[song_id])\n",
    "    x = track_features_dict[song_track_mapping[str(song_id_key)]]\n",
    "#     y_pred = model.net.predict(np.array([x]))\n",
    "    norm_sum += np.linalg.norm(y)**2\n",
    "print(norm_sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_json = model.net.to_json()\n",
    "with open('params/model_params_v1.json', \"w\") as f:\n",
    "    f.write(model_json)\n",
    "model.net.save_weights(\"params/model_params_v1.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make one-hot genre encodings:\n",
    "genres = {'Blues':0,\n",
    " 'Country':1,\n",
    " 'Electronic':2,\n",
    " 'Folk':3,\n",
    " 'Jazz':4,\n",
    " 'Latin':5,\n",
    " 'Metal':6,\n",
    " 'New':7,\n",
    " 'Pop':8,\n",
    " 'Punk':9,\n",
    " 'Rap':10,\n",
    " 'Reggae':11,\n",
    " 'RnB':12,\n",
    " 'Rock':13,\n",
    " 'World':14}\n",
    "\n",
    "with open('data/track-genre-mapping.json', 'r') as fp:\n",
    "    track_genre_dict = json.load(fp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2367\n"
     ]
    }
   ],
   "source": [
    "track_genre_onehot_dict = {}\n",
    "f = open(\"data/track_ids_for_chroma.txt\", \"r\")\n",
    "track_ids = set()\n",
    "counter = 0\n",
    "for line in f:\n",
    "    track_id = line.strip()\n",
    "    genre = track_genre_dict.get(track_id)\n",
    "    if genre:\n",
    "        track_ids.add(track_id)\n",
    "        \n",
    "for track_id in track_ids:\n",
    "    genre = track_genre_dict.get(track_id)\n",
    "    idx = genres[genre]\n",
    "    onehot = np.zeros(15)\n",
    "    onehot[idx] = 1.0\n",
    "    track_genre_onehot_dict[track_id] = onehot\n",
    "    counter += 1\n",
    "print(counter)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
