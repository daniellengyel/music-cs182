{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# usual imports\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import glob\n",
    "import datetime\n",
    "import sqlite3\n",
    "import pandas as pd\n",
    "import numpy as np # get it at: http://numpy.scipy.org/\n",
    "# path to the Million Song Dataset subset (uncompressed)\n",
    "# CHANGE IT TO YOUR LOCAL CONFIGURATION\n",
    "msd_subset_path='./data/MSD/MillionSongSubset'\n",
    "msd_subset_data_path=os.path.join(msd_subset_path,'data')\n",
    "msd_subset_addf_path=os.path.join(msd_subset_path,'AdditionalFiles')\n",
    "assert os.path.isdir(msd_subset_path),'wrong path' # sanity check\n",
    "# path to the Million Song Dataset code\n",
    "# CHANGE IT TO YOUR LOCAL CONFIGURATION\n",
    "msd_code_path='./data/MSD/MSongsDB'\n",
    "assert os.path.isdir(msd_code_path),'wrong path' # sanity check\n",
    "# we add some paths to python so we can import MSD code\n",
    "# Ubuntu: you can change the environment variable PYTHONPATH\n",
    "# in your .bashrc file so you do not have to type these lines\n",
    "sys.path.append(os.path.join(msd_code_path,'PythonSrc') )\n",
    "\n",
    "taste_profile_data_path=\"./data/TinyEchoNestTasteProfileSubset.csv\"\n",
    "assert os.path.isfile(taste_profile_data_path)\n",
    "\n",
    "# imports specific to the MSD\n",
    "import hdf5_getters as GETTERS\n",
    "\n",
    "from pyspark.ml.recommendation import ALS\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml.recommendation import ALS\n",
    "from pyspark.sql import Row"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_taste_subset(path='./data/FullEchoNestTasteProfileSubset.txt', \n",
    "                        to_path='./data/TeenyTinyEchoNestTasteProfileSubset.csv', downsample=0.001):\n",
    "    data = pd.read_csv(path, sep=\"\\t\", header=None)\n",
    "    data.columns = ['user', 'song', 'play_count']\n",
    "    data.astype({'user': np.str, 'song': np.str, 'play_count': np.int32})\n",
    "    data.sample(frac=downsample).to_csv(to_path, index=False)\n",
    "# the following function simply gives us a nice string for\n",
    "# a time lag in seconds\n",
    "def strtimedelta(starttime,stoptime):\n",
    "    return str(datetime.timedelta(seconds=stoptime-starttime))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(taste_profile_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>song</th>\n",
       "      <th>play_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>293073e399f3d3b3dc38b8043175d23902645f4c</td>\n",
       "      <td>SORGAPU12A8AE4585E</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>b5f15729a33087a849df1747f99adf699dc154d9</td>\n",
       "      <td>SOJYCEU12A6701FBAA</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>e35f2113adc67b2ce5372a2eff4115f5d38133c7</td>\n",
       "      <td>SOBEGGQ12A8C1341E0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>e7d091018fede4482d03eddb414cd7e245cd476a</td>\n",
       "      <td>SOVVHRL12A6D4F6BF7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>d7de5fcb8f1fa64e4eaab85a51f7e59d0c8040d7</td>\n",
       "      <td>SOQWZHE12A67AE10FF</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       user                song  play_count\n",
       "0  293073e399f3d3b3dc38b8043175d23902645f4c  SORGAPU12A8AE4585E           1\n",
       "1  b5f15729a33087a849df1747f99adf699dc154d9  SOJYCEU12A6701FBAA           1\n",
       "2  e35f2113adc67b2ce5372a2eff4115f5d38133c7  SOBEGGQ12A8C1341E0           7\n",
       "3  e7d091018fede4482d03eddb414cd7e245cd476a  SOVVHRL12A6D4F6BF7           1\n",
       "4  d7de5fcb8f1fa64e4eaab85a51f7e59d0c8040d7  SOQWZHE12A67AE10FF           5"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(483736, 3)\n"
     ]
    }
   ],
   "source": [
    "song_id = data.iloc[1]['song']\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = \"e45503e1d7c3c88fcea0da0947292afdbb26d27c\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To check if the data we are using is also in the MSD\n",
    "Running the cell to get all valid_zone_ids showed that all songs in data are valid songs in the MSD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the song ids which are also in the database. \n",
    "valid_song_ids = []\n",
    "\n",
    "for song_id in data['song'].values:\n",
    "    # let's redo all this work in SQLite in a few seconds\n",
    "    t1 = time.time()\n",
    "    # connect to database to get the metadata from MSD\n",
    "    conn = sqlite3.connect(os.path.join(msd_subset_addf_path,\n",
    "                                        'subset_track_metadata.db'))\n",
    "\n",
    "    q = \"SELECT DISTINCT song_id,artist_id,artist_name,Count(track_id) FROM songs\"\n",
    "    q += \" WHERE song_id='\" + song_id + \"'\"\n",
    "    res = conn.execute(q)\n",
    "    res = res.fetchall()\n",
    "    conn.close()\n",
    "    t2 = time.time()\n",
    "    if res[0] is not None:\n",
    "        valid_song_ids.append(song_id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "48374"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(valid_song_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fit model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def tune_ALS(train_data, validation_data, maxIter, regParams, ranks):\n",
    "    \"\"\"\n",
    "    grid search function to select the best model based on RMSE of\n",
    "    validation data\n",
    "    Parameters\n",
    "    ----------\n",
    "    train_data: spark DF with columns ['user', 'song', 'play_count']\n",
    "    \n",
    "    validation_data: spark DF with columns ['user', 'song', 'play_count']\n",
    "    \n",
    "    maxIter: int, max number of learning iterations\n",
    "    \n",
    "    regParams: list of float, one dimension of hyper-param tuning grid\n",
    "    \n",
    "    ranks: list of float, one dimension of hyper-param tuning grid\n",
    "    \n",
    "    Return\n",
    "    ------\n",
    "    The best fitted ALS model with lowest RMSE score on validation data\n",
    "    \"\"\"\n",
    "    # initial\n",
    "    min_error = float('inf')\n",
    "    best_rank = -1\n",
    "    best_regularization = 0\n",
    "    best_model = None\n",
    "    for rank in ranks:\n",
    "        for reg in regParams:\n",
    "            # get ALS model\n",
    "            # Note we set cold start strategy to 'drop' to ensure we don't get NaN evaluation metrics\n",
    "            als = ALS(userCol=\"user\", itemCol=\"song\", ratingCol=\"play_count\", implicitPrefs=True, alpha=40).setMaxIter(maxIter).setRank(rank).setRegParam(reg).setColdStartStrategy(\"drop\")\n",
    "            # train ALS model\n",
    "            model = als.fit(train_data)\n",
    "            # evaluate the model by computing the RMSE on the validation data\n",
    "            predictions = model.transform(validation_data)  # give Nan to data that hasn't been seen before. cold_start drops those\n",
    "            evaluator = RegressionEvaluator(metricName=\"rmse\",\n",
    "                                            labelCol=\"play_count\",\n",
    "                                            predictionCol=\"prediction\")\n",
    "            rmse = evaluator.evaluate(predictions)\n",
    "            print('{} latent factors and regularization = {}: '\n",
    "                  'validation RMSE is {}'.format(rank, reg, rmse))\n",
    "            if rmse < min_error:\n",
    "                min_error = rmse\n",
    "                best_rank = rank\n",
    "                best_regularization = reg\n",
    "                best_model = model\n",
    "    print('\\nThe best model has {} latent factors and '\n",
    "          'regularization = {}'.format(best_rank, best_regularization))\n",
    "    return best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_mapping = {}\n",
    "last_user = 0\n",
    "song_mapping = {}\n",
    "last_song = 0\n",
    "for idx, row in data.iterrows():\n",
    "    if row[\"user\"] not in user_mapping:\n",
    "        user_mapping[row[\"user\"]] = last_user\n",
    "        last_user += 1\n",
    "    if row[\"song\"] not in song_mapping:\n",
    "        song_mapping[row[\"song\"]] = last_song\n",
    "        last_song += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "prep_data = data.copy()\n",
    "prep_data[\"user\"] = prep_data[\"user\"].map(lambda x: user_mapping[x])\n",
    "prep_data[\"song\"] = prep_data[\"song\"].map(lambda x: song_mapping[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_frac = 0.7\n",
    "train_data = prep_data.iloc[:int(prep_data.shape[0] * split_frac)]\n",
    "val_data = prep_data.iloc[int(prep_data.shape[0] * split_frac):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark_data = spark.createDataFrame(prep_data)\n",
    "(training, val) = spark_data.randomSplit([0.8, 0.2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>song</th>\n",
       "      <th>play_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user  song  play_count\n",
       "0     0     0           1\n",
       "1     1     1           1\n",
       "2     2     2           7\n",
       "3     3     3           1\n",
       "4     4     4           5"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50 latent factors and regularization = 0.001: validation RMSE is 5.62476611477\n",
      "50 latent factors and regularization = 0.01: validation RMSE is 5.62476757102\n",
      "50 latent factors and regularization = 0.1: validation RMSE is 5.62477833389\n",
      "50 latent factors and regularization = 1: validation RMSE is 5.62474339512\n",
      "50 latent factors and regularization = 2: validation RMSE is 5.6246331639\n",
      "\n",
      "The best model has 50 latent factors and regularization = 2\n"
     ]
    }
   ],
   "source": [
    "model = tune_ALS(training, val, 20, [1e-3, 1e-2, 1e-1, 1, 2], [50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ALS_dd3b6079bc21"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "music-cs182",
   "language": "python",
   "name": "music-cs182"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
